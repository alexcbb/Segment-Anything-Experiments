{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Anything - Experiments\n",
    "We believe that the abilities of the released foundation model, **Segment Anything Model** (*SAM*), can serve the purpose of creating a *generalizable object-centric representation* model. Indeed, its capacity to segment any object into images in a zero-shot manner would permit to serve as a powerful prior for object discovery.\n",
    "\n",
    "That's why we want to experiment with it, to see how we can leverage its knowledge to train new models through *knowledge distillation* later on.\n",
    "\n",
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages needed for the project \n",
    "from segment_anything import SamAutomaticMaskGenerator, SamPredictor, sam_model_registry\n",
    "from expe.dataset import YCBDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "using_colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "We first define some utility functions to visualize the masks, points and boxes around objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax):\n",
    "    color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model\n",
    "Three different size of checkpoints are available for the model. In our experiments, we will use the default size (ViT-H). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "device = \"cuda\"\n",
    "sam = sam_model_registry[\"default\"](checkpoint=\"sam_vit_h_4b8939.pth\")\n",
    "sam.to(device=device)\n",
    "\n",
    "# Defining a predictor and a mask generator\n",
    "predictor = SamPredictor(sam)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the datasets\n",
    "For our experiments, we will test the abilities of *SAM* on several real world objects dataset. This could permit us to confirm if it could be correctly used to be deployed in such a scenario. \n",
    "\n",
    "The **YCB-Video** dataset used for 6D pose estimation seems to be a good starting point to evaluate the *zero-shot segmentation capabilities* of the model. It is compose of thousands of images containing 21 different objects in 80 different scenes with different viewpoints.\n",
    "\n",
    "The **ARMBench** dataset is a perception and manipulation benchmark in a robotic pick-and-place setting. It contains several scenes with different objects and different challenges such as Object segmentation, Object Identification, and Defect Detection on images and videos.\n",
    "\n",
    "To handle the data from these datasets, we created custom Pytorch Dataset classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ycb = YCBDataset(\"./../../Datasets/ycb-video/image_sets/train.txt\", \"./../../Datasets/ycb-video/data\")\n",
    "dataloader_ycb = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "dataset_arm = ARMDataset(\"\", \"\")\n",
    "dataloader_arm = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on images\n",
    "In this section, we will experiment several things on randomly sampled images from YCB-Video dataset. \n",
    "\n",
    "### Show images\n",
    "We first show some random images to see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 480, 640)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 480, 640) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m#predictor.set_image(np_img)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m plt\u001b[39m.\u001b[39;49mimshow(image)\n\u001b[1;32m     17\u001b[0m show_points(input_point, input_label, plt\u001b[39m.\u001b[39mgca())\n\u001b[1;32m     18\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39mon\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sam/lib/python3.10/site-packages/matplotlib/pyplot.py:2695\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2689\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mimshow)\n\u001b[1;32m   2690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(\n\u001b[1;32m   2691\u001b[0m         X, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, aspect\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, interpolation\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2692\u001b[0m         alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, origin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, extent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2693\u001b[0m         interpolation_stage\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, filternorm\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, filterrad\u001b[39m=\u001b[39m\u001b[39m4.0\u001b[39m,\n\u001b[1;32m   2694\u001b[0m         resample\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, url\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2695\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39;49mimshow(\n\u001b[1;32m   2696\u001b[0m         X, cmap\u001b[39m=\u001b[39;49mcmap, norm\u001b[39m=\u001b[39;49mnorm, aspect\u001b[39m=\u001b[39;49maspect,\n\u001b[1;32m   2697\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation, alpha\u001b[39m=\u001b[39;49malpha, vmin\u001b[39m=\u001b[39;49mvmin,\n\u001b[1;32m   2698\u001b[0m         vmax\u001b[39m=\u001b[39;49mvmax, origin\u001b[39m=\u001b[39;49morigin, extent\u001b[39m=\u001b[39;49mextent,\n\u001b[1;32m   2699\u001b[0m         interpolation_stage\u001b[39m=\u001b[39;49minterpolation_stage,\n\u001b[1;32m   2700\u001b[0m         filternorm\u001b[39m=\u001b[39;49mfilternorm, filterrad\u001b[39m=\u001b[39;49mfilterrad, resample\u001b[39m=\u001b[39;49mresample,\n\u001b[1;32m   2701\u001b[0m         url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}),\n\u001b[1;32m   2702\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2703\u001b[0m     sci(__ret)\n\u001b[1;32m   2704\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/miniconda3/envs/sam/lib/python3.10/site-packages/matplotlib/__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1444\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1445\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1446\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/miniconda3/envs/sam/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5665\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5658\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[1;32m   5659\u001b[0m                       interpolation\u001b[39m=\u001b[39minterpolation, origin\u001b[39m=\u001b[39morigin,\n\u001b[1;32m   5660\u001b[0m                       extent\u001b[39m=\u001b[39mextent, filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[1;32m   5661\u001b[0m                       filterrad\u001b[39m=\u001b[39mfilterrad, resample\u001b[39m=\u001b[39mresample,\n\u001b[1;32m   5662\u001b[0m                       interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5663\u001b[0m                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 5665\u001b[0m im\u001b[39m.\u001b[39;49mset_data(X)\n\u001b[1;32m   5666\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5667\u001b[0m \u001b[39mif\u001b[39;00m im\u001b[39m.\u001b[39mget_clip_path() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5668\u001b[0m     \u001b[39m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sam/lib/python3.10/site-packages/matplotlib/image.py:710\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A[:, :, \u001b[39m0\u001b[39m]\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]):\n\u001b[0;32m--> 710\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid shape \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for image data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    711\u001b[0m                     \u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mshape))\n\u001b[1;32m    713\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    714\u001b[0m     \u001b[39m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    715\u001b[0m     \u001b[39m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[39m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[39m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     high \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_A\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger) \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 480, 640) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get some images\n",
    "images_ycb =  list(enumerate(dataloader_ycb))[:5]\n",
    "images_arm =  list(enumerate(dataloader_arm))[:5]\n",
    "\n",
    "# Show the images\n",
    "for image in images_ycb:\n",
    "    np_img = np.array(image)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(np_img)\n",
    "    plt.show() \n",
    "    \n",
    "for image in images_arm:\n",
    "    np_img = np.array(image)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(np_img)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict masks with points\n",
    "In the following section, we will experiment the ability of *SAM* to segment objects with a Point prompt and see how it can handle ambiguities.\n",
    "\n",
    "A Point prompt is in the format (x, y) and is given with a label 1 (for foreground) and 0 (for background).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt point and label\n",
    "input_point = np.array([[500, 375]])\n",
    "input_label = np.array([1])\n",
    "\n",
    "# Show point on some images\n",
    "for image in im:\n",
    "    np_img = np.array(image)\n",
    "    predictor.set_image(np_img)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(image)\n",
    "    show_points(input_point, input_label, plt.gca())\n",
    "    plt.axis('on')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now show what the model predicts for the given prompt. It should return masks and a confidence score (quality prediction) but also a low resolution mask logits that can be used for the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the masks\n",
    "for image in im:\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=input_point,\n",
    "        point_labels=input_label,\n",
    "        multimask_output=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use multiple points to handle a single object like in the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also exist negative points that permits to exclude some parts from the segmentation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict mask with box\n",
    "In the following, we will experiment the capabilities of *SAM* to segment objects with a box prompt. We will first give it manual prompt and then try to combine it with the prediction of a YOLO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "sam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
